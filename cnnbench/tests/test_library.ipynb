{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from library import Graph, GraphLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95mGraph Library with configurations:\u001b[0m\n",
      "{'dataset': 'CIFAR10', 'classes': 10, 'input_channels': 3, 'image_size': 64, 'data_dir': '/scratch/gpfs/stuli/pytorch_datasets/', 'manual_dir': None, 'models_dir': '/scratch/gpfs/stuli/cnnbench_models/', 'epochs': 10, 'train_batch_size': 256, 'test_batch_size': 512, 'optimizer': 'Adam', 'lr': 0.001, 'scheduler': 'CosineAnnealingWarmRestarts', 'scheduler_args': {'T_0': 5}, 'module_vertices': 4, 'head_vertices': 4, 'max_edges': 9, 'max_modules': 2, 'base_ops': ['conv5x5-bn-relu', 'conv3x3-bn-relu', 'conv1x1-bn-relu', 'maxpool3x3'], 'default_channels': 128, 'default_stride': 1, 'flatten_ops': ['global-avg-pool', 'flatten'], 'dense_ops': ['dense-1024', 'dense-4096', 'dropout-p5', 'dropout-p4'], 'hash_algo': 'sha256'}\n",
      "\u001b[95mNumber of graphs:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "graphLib = GraphLib(config='./config_test.yaml')\n",
    "print(graphLib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95mGenerating modules...\u001b[0m\n",
      "\u001b[95mUsing 4 vertices, 4 labels, max 9 edges\u001b[0m\n",
      "\t\u001b[92mGenerated up to 3 vertices: 8 modules (8 without hashing)\u001b[0m\n",
      "\t\u001b[92mGenerated up to 4 vertices: 156 modules (168 without hashing)\u001b[0m\n",
      "\n",
      "\u001b[95mGenerating heads...\u001b[0m\n",
      "\u001b[95mUsing 4 vertices, 6 labels\u001b[0m\n",
      "\t\u001b[92mGenerated up to 4 vertices: 2 heads (2 without hashing)\u001b[0m\n",
      "\n",
      "\u001b[95mGenerating graphs...\u001b[0m\n",
      "\u001b[95mUsing max 2 modules\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f1c19fec874459b96ea95a04c46528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating CNNs with 1 module(s)', max=156.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\u001b[92mGenerated up to 1 modules: 312 graphs\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e961ec3a9404578846371b6e0af8c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating CNNs with 2 module(s)', max=24336.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\u001b[92mGenerated up to 2 modules: 48824 graphs\u001b[0m\n",
      "\u001b[92mGraph library created!\u001b[0m \n",
      "48824 graphs within the design space.\n"
     ]
    }
   ],
   "source": [
    "graphLib.build_library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mDataset saved to:\u001b[0m ./dataset.json\n"
     ]
    }
   ],
   "source": [
    "graphLib.save_dataset('./dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[95mGraph Library with configurations:\u001b[0m\n",
       "{'dataset': 'CIFAR10', 'classes': 10, 'input_channels': 3, 'image_size': 28, 'data_dir': '/scratch/gpfs/stuli/pytorch_datasets/', 'manual_dir': None, 'train_batch_size': 256, 'test_batch_size': 512, 'module_vertices': 4, 'head_vertices': 4, 'max_edges': 9, 'max_modules': 2, 'base_ops': ['conv5x5-bn-relu', 'conv3x3-bn-relu', 'conv1x1-bn-relu', 'maxpool3x3'], 'default_channels': 128, 'default_stride': 1, 'flatten_ops': ['global-avg-pool', 'flatten'], 'dense_ops': ['dense-1024', 'dense-4096', 'dropout-p5', 'dropout-p4'], 'hash_algo': 'sha256'}\n",
       "\u001b[95mNumber of graphs:\u001b[0m 48824"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphLib_new = GraphLib.load_from_dataset('./dataset.json')\n",
    "graphLib_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[95mModel parameters:\u001b[0m None\n",
       "\u001b[95mAccuracies:\u001b[0m {'train': None, 'val': None, 'test': None}\n",
       "\u001b[95mEmbedding:\u001b[0m None\n",
       "\u001b[95mHash:\u001b[0m 68510bcf50e51d05fef802b1af7a08334b76275fae640836ceb787e5af9dcd65\n",
       "\u001b[96mModule:\u001b[0m\n",
       "[[0 1 0]\n",
       " [0 0 1]\n",
       " [0 0 0]]\n",
       "\u001b[96mLabels:\u001b[0m['input', 'conv5x5-bn-relu', 'output']\n",
       "\u001b[96mModule:\u001b[0m\n",
       "[[0 1 0 0]\n",
       " [0 0 1 0]\n",
       " [0 0 0 1]\n",
       " [0 0 0 0]]\n",
       "\u001b[96mLabels:\u001b[0m['input', 'flatten', 'dense_classes', 'output']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from library import Graph, GraphLib\n",
    "\n",
    "graphLib = GraphLib.load_from_dataset('./dataset.json')\n",
    "\n",
    "graphLib.library[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNBenchModel(\n",
      "  (op_m0_v1): Sequential(\n",
      "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (proj_m0_v1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (proj_m0): Conv2d(3, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (op_m1_v2): Linear(in_features=460800, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from library import Graph, GraphLib\n",
    "\n",
    "from model_builder import CNNBenchModel\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "graphLib = GraphLib.load_from_dataset('./dataset.json')\n",
    "\n",
    "inp = torch.rand(64, 3, graphLib.config['image_size'], graphLib.config['image_size'])\n",
    "inp = inp.to(device)\n",
    "\n",
    "# for i in range(len(graphLib)):\n",
    "#     model = CNNBenchModel(graphLib.config, graphLib.library[i])\n",
    "#     model.to(device)\n",
    "#     logits = model(inp)\n",
    "#     print(f'\\r{i}/{len(graphLib)}', end='')\n",
    "model = CNNBenchModel(graphLib.config, graphLib.library[1])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4618390"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:\n",
      "\u001b[95mModel parameters:\u001b[0m None\n",
      "\u001b[95mAccuracies:\u001b[0m {'train': None, 'val': None, 'test': None}\n",
      "\u001b[95mEmbedding:\u001b[0m None\n",
      "\u001b[95mHash:\u001b[0m 68510bcf50e51d05fef802b1af7a08334b76275fae640836ceb787e5af9dcd65\n",
      "\u001b[96mModule:\u001b[0m\n",
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 0]]\n",
      "\u001b[96mLabels:\u001b[0m['input', 'conv5x5-bn-relu', 'output']\n",
      "\u001b[96mModule:\u001b[0m\n",
      "[[0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [0 0 0 0]]\n",
      "\u001b[96mLabels:\u001b[0m['input', 'flatten', 'dense_classes', 'output']\n",
      "\n",
      "\n",
      "\u001b[94mLoading Training dataset\u001b[0m\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: /scratch/gpfs/stuli/pytorch_datasets/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=32, interpolation=bilinear)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
      "           )\n",
      "\u001b[94mLoading Test dataset\u001b[0m\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: /scratch/gpfs/stuli/pytorch_datasets/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=32, interpolation=bilinear)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
      "           )\n",
      "Train Epoch: 0 [     0/ 50000 (0%)]\tLearning Rate: 0.001000\tLoss: 2.398569\n",
      "Train Epoch: 0 [  2560/ 50000 (5%)]\tLearning Rate: 0.001000\tLoss: 29.247425\n",
      "Train Epoch: 0 [  5120/ 50000 (10%)]\tLearning Rate: 0.000999\tLoss: 11.416993\n",
      "Train Epoch: 0 [  7680/ 50000 (15%)]\tLearning Rate: 0.000998\tLoss: 8.163881\n",
      "Train Epoch: 0 [ 10240/ 50000 (20%)]\tLearning Rate: 0.000996\tLoss: 4.744193\n",
      "Train Epoch: 0 [ 12800/ 50000 (26%)]\tLearning Rate: 0.000994\tLoss: 4.248237\n",
      "Train Epoch: 0 [ 15360/ 50000 (31%)]\tLearning Rate: 0.000991\tLoss: 3.146968\n",
      "Train Epoch: 0 [ 17920/ 50000 (36%)]\tLearning Rate: 0.000987\tLoss: 2.541626\n",
      "Train Epoch: 0 [ 20480/ 50000 (41%)]\tLearning Rate: 0.000984\tLoss: 3.219798\n",
      "Train Epoch: 0 [ 23040/ 50000 (46%)]\tLearning Rate: 0.000979\tLoss: 2.786646\n",
      "Train Epoch: 0 [ 25600/ 50000 (51%)]\tLearning Rate: 0.000975\tLoss: 2.088935\n",
      "Train Epoch: 0 [ 28160/ 50000 (56%)]\tLearning Rate: 0.000969\tLoss: 2.812321\n",
      "Train Epoch: 0 [ 30720/ 50000 (61%)]\tLearning Rate: 0.000963\tLoss: 2.157907\n",
      "Train Epoch: 0 [ 33280/ 50000 (66%)]\tLearning Rate: 0.000957\tLoss: 2.587747\n",
      "Train Epoch: 0 [ 35840/ 50000 (71%)]\tLearning Rate: 0.000950\tLoss: 2.873943\n",
      "Train Epoch: 0 [ 38400/ 50000 (77%)]\tLearning Rate: 0.000943\tLoss: 2.966796\n",
      "Train Epoch: 0 [ 40960/ 50000 (82%)]\tLearning Rate: 0.000936\tLoss: 2.565445\n",
      "Train Epoch: 0 [ 43520/ 50000 (87%)]\tLearning Rate: 0.000928\tLoss: 2.803256\n",
      "Train Epoch: 0 [ 46080/ 50000 (92%)]\tLearning Rate: 0.000919\tLoss: 2.776190\n",
      "Train Epoch: 0 [ 48640/ 50000 (97%)]\tLearning Rate: 0.000910\tLoss: 2.579693\n",
      "\n",
      "Train set: Average loss: 2.0337, Accuracy: 25587/50000 (51%)\n",
      "Test set: Average loss: 2.2156, Accuracy: 4844/10000 (48%)\n",
      "\n",
      "Train Epoch: 1 [     0/ 50000 (0%)]\tLearning Rate: 0.000905\tLoss: 2.095207\n",
      "Train Epoch: 1 [  2560/ 50000 (5%)]\tLearning Rate: 0.000895\tLoss: 1.813326\n",
      "Train Epoch: 1 [  5120/ 50000 (10%)]\tLearning Rate: 0.000885\tLoss: 2.204358\n",
      "Train Epoch: 1 [  7680/ 50000 (15%)]\tLearning Rate: 0.000874\tLoss: 2.460125\n",
      "Train Epoch: 1 [ 10240/ 50000 (20%)]\tLearning Rate: 0.000864\tLoss: 2.259773\n",
      "Train Epoch: 1 [ 12800/ 50000 (26%)]\tLearning Rate: 0.000852\tLoss: 1.706081\n",
      "Train Epoch: 1 [ 15360/ 50000 (31%)]\tLearning Rate: 0.000841\tLoss: 1.854532\n",
      "Train Epoch: 1 [ 17920/ 50000 (36%)]\tLearning Rate: 0.000829\tLoss: 2.092776\n",
      "Train Epoch: 1 [ 20480/ 50000 (41%)]\tLearning Rate: 0.000817\tLoss: 2.039490\n",
      "Train Epoch: 1 [ 23040/ 50000 (46%)]\tLearning Rate: 0.000804\tLoss: 1.770419\n",
      "Train Epoch: 1 [ 25600/ 50000 (51%)]\tLearning Rate: 0.000791\tLoss: 2.011686\n",
      "Train Epoch: 1 [ 28160/ 50000 (56%)]\tLearning Rate: 0.000778\tLoss: 2.021478\n",
      "Train Epoch: 1 [ 30720/ 50000 (61%)]\tLearning Rate: 0.000765\tLoss: 1.835935\n",
      "Train Epoch: 1 [ 33280/ 50000 (66%)]\tLearning Rate: 0.000751\tLoss: 1.943417\n",
      "Train Epoch: 1 [ 35840/ 50000 (71%)]\tLearning Rate: 0.000737\tLoss: 2.025981\n",
      "Train Epoch: 1 [ 38400/ 50000 (77%)]\tLearning Rate: 0.000723\tLoss: 1.750328\n",
      "Train Epoch: 1 [ 40960/ 50000 (82%)]\tLearning Rate: 0.000708\tLoss: 1.892032\n",
      "Train Epoch: 1 [ 43520/ 50000 (87%)]\tLearning Rate: 0.000694\tLoss: 1.731976\n",
      "Train Epoch: 1 [ 46080/ 50000 (92%)]\tLearning Rate: 0.000679\tLoss: 1.576151\n",
      "Train Epoch: 1 [ 48640/ 50000 (97%)]\tLearning Rate: 0.000664\tLoss: 1.557906\n",
      "\n",
      "Train set: Average loss: 1.5527, Accuracy: 28962/50000 (58%)\n",
      "Test set: Average loss: 1.8377, Accuracy: 5368/10000 (54%)\n",
      "\n",
      "Train Epoch: 2 [     0/ 50000 (0%)]\tLearning Rate: 0.000655\tLoss: 1.511259\n",
      "Train Epoch: 2 [  2560/ 50000 (5%)]\tLearning Rate: 0.000639\tLoss: 1.440321\n",
      "Train Epoch: 2 [  5120/ 50000 (10%)]\tLearning Rate: 0.000624\tLoss: 1.490587\n",
      "Train Epoch: 2 [  7680/ 50000 (15%)]\tLearning Rate: 0.000608\tLoss: 1.520310\n",
      "Train Epoch: 2 [ 10240/ 50000 (20%)]\tLearning Rate: 0.000592\tLoss: 1.415172\n",
      "Train Epoch: 2 [ 12800/ 50000 (26%)]\tLearning Rate: 0.000577\tLoss: 1.388999\n",
      "Train Epoch: 2 [ 15360/ 50000 (31%)]\tLearning Rate: 0.000561\tLoss: 1.754274\n",
      "Train Epoch: 2 [ 17920/ 50000 (36%)]\tLearning Rate: 0.000545\tLoss: 1.821383\n",
      "Train Epoch: 2 [ 20480/ 50000 (41%)]\tLearning Rate: 0.000529\tLoss: 1.309485\n",
      "Train Epoch: 2 [ 23040/ 50000 (46%)]\tLearning Rate: 0.000513\tLoss: 1.203606\n",
      "Train Epoch: 2 [ 25600/ 50000 (51%)]\tLearning Rate: 0.000497\tLoss: 1.377797\n",
      "Train Epoch: 2 [ 28160/ 50000 (56%)]\tLearning Rate: 0.000481\tLoss: 1.269645\n",
      "Train Epoch: 2 [ 30720/ 50000 (61%)]\tLearning Rate: 0.000465\tLoss: 1.163071\n",
      "Train Epoch: 2 [ 33280/ 50000 (66%)]\tLearning Rate: 0.000449\tLoss: 1.394418\n",
      "Train Epoch: 2 [ 35840/ 50000 (71%)]\tLearning Rate: 0.000433\tLoss: 1.316025\n",
      "Train Epoch: 2 [ 38400/ 50000 (77%)]\tLearning Rate: 0.000417\tLoss: 1.315670\n",
      "Train Epoch: 2 [ 40960/ 50000 (82%)]\tLearning Rate: 0.000401\tLoss: 1.425723\n",
      "Train Epoch: 2 [ 43520/ 50000 (87%)]\tLearning Rate: 0.000386\tLoss: 1.231770\n",
      "Train Epoch: 2 [ 46080/ 50000 (92%)]\tLearning Rate: 0.000370\tLoss: 1.026434\n",
      "Train Epoch: 2 [ 48640/ 50000 (97%)]\tLearning Rate: 0.000355\tLoss: 1.322406\n",
      "\n",
      "Train set: Average loss: 1.1652, Accuracy: 32017/50000 (64%)\n",
      "Test set: Average loss: 1.5099, Accuracy: 5637/10000 (56%)\n",
      "\n",
      "Train Epoch: 3 [     0/ 50000 (0%)]\tLearning Rate: 0.000345\tLoss: 1.259147\n",
      "Train Epoch: 3 [  2560/ 50000 (5%)]\tLearning Rate: 0.000330\tLoss: 1.050467\n",
      "Train Epoch: 3 [  5120/ 50000 (10%)]\tLearning Rate: 0.000315\tLoss: 0.958247\n",
      "Train Epoch: 3 [  7680/ 50000 (15%)]\tLearning Rate: 0.000301\tLoss: 1.215098\n",
      "Train Epoch: 3 [ 10240/ 50000 (20%)]\tLearning Rate: 0.000286\tLoss: 1.010422\n",
      "Train Epoch: 3 [ 12800/ 50000 (26%)]\tLearning Rate: 0.000272\tLoss: 1.022779\n",
      "Train Epoch: 3 [ 15360/ 50000 (31%)]\tLearning Rate: 0.000257\tLoss: 1.137315\n",
      "Train Epoch: 3 [ 17920/ 50000 (36%)]\tLearning Rate: 0.000244\tLoss: 0.902773\n",
      "Train Epoch: 3 [ 20480/ 50000 (41%)]\tLearning Rate: 0.000230\tLoss: 0.951449\n",
      "Train Epoch: 3 [ 23040/ 50000 (46%)]\tLearning Rate: 0.000217\tLoss: 0.913514\n",
      "Train Epoch: 3 [ 25600/ 50000 (51%)]\tLearning Rate: 0.000204\tLoss: 0.991180\n",
      "Train Epoch: 3 [ 28160/ 50000 (56%)]\tLearning Rate: 0.000191\tLoss: 0.919821\n",
      "Train Epoch: 3 [ 30720/ 50000 (61%)]\tLearning Rate: 0.000178\tLoss: 0.968058\n",
      "Train Epoch: 3 [ 33280/ 50000 (66%)]\tLearning Rate: 0.000166\tLoss: 1.003552\n",
      "Train Epoch: 3 [ 35840/ 50000 (71%)]\tLearning Rate: 0.000154\tLoss: 1.033191\n",
      "Train Epoch: 3 [ 38400/ 50000 (77%)]\tLearning Rate: 0.000143\tLoss: 0.904565\n",
      "Train Epoch: 3 [ 40960/ 50000 (82%)]\tLearning Rate: 0.000132\tLoss: 0.852893\n",
      "Train Epoch: 3 [ 43520/ 50000 (87%)]\tLearning Rate: 0.000121\tLoss: 0.815621\n",
      "Train Epoch: 3 [ 46080/ 50000 (92%)]\tLearning Rate: 0.000111\tLoss: 0.834241\n",
      "Train Epoch: 3 [ 48640/ 50000 (97%)]\tLearning Rate: 0.000101\tLoss: 0.931090\n",
      "\n",
      "Train set: Average loss: 0.8155, Accuracy: 36227/50000 (72%)\n",
      "Test set: Average loss: 1.1514, Accuracy: 6247/10000 (62%)\n",
      "\n",
      "Train Epoch: 4 [     0/ 50000 (0%)]\tLearning Rate: 0.000095\tLoss: 0.804603\n",
      "Train Epoch: 4 [  2560/ 50000 (5%)]\tLearning Rate: 0.000086\tLoss: 0.757377\n",
      "Train Epoch: 4 [  5120/ 50000 (10%)]\tLearning Rate: 0.000077\tLoss: 0.857539\n",
      "Train Epoch: 4 [  7680/ 50000 (15%)]\tLearning Rate: 0.000069\tLoss: 0.883035\n",
      "Train Epoch: 4 [ 10240/ 50000 (20%)]\tLearning Rate: 0.000061\tLoss: 0.753107\n",
      "Train Epoch: 4 [ 12800/ 50000 (26%)]\tLearning Rate: 0.000054\tLoss: 0.834437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [ 15360/ 50000 (31%)]\tLearning Rate: 0.000047\tLoss: 0.739877\n",
      "Train Epoch: 4 [ 17920/ 50000 (36%)]\tLearning Rate: 0.000040\tLoss: 0.793790\n",
      "Train Epoch: 4 [ 20480/ 50000 (41%)]\tLearning Rate: 0.000034\tLoss: 0.887421\n",
      "Train Epoch: 4 [ 23040/ 50000 (46%)]\tLearning Rate: 0.000029\tLoss: 0.815059\n",
      "Train Epoch: 4 [ 25600/ 50000 (51%)]\tLearning Rate: 0.000023\tLoss: 0.761585\n",
      "Train Epoch: 4 [ 28160/ 50000 (56%)]\tLearning Rate: 0.000019\tLoss: 0.855973\n",
      "Train Epoch: 4 [ 30720/ 50000 (61%)]\tLearning Rate: 0.000015\tLoss: 0.795239\n",
      "Train Epoch: 4 [ 33280/ 50000 (66%)]\tLearning Rate: 0.000011\tLoss: 0.825276\n",
      "Train Epoch: 4 [ 35840/ 50000 (71%)]\tLearning Rate: 0.000008\tLoss: 0.764152\n",
      "Train Epoch: 4 [ 38400/ 50000 (77%)]\tLearning Rate: 0.000005\tLoss: 0.821767\n",
      "Train Epoch: 4 [ 40960/ 50000 (82%)]\tLearning Rate: 0.000003\tLoss: 0.734719\n",
      "Train Epoch: 4 [ 43520/ 50000 (87%)]\tLearning Rate: 0.000002\tLoss: 0.841771\n",
      "Train Epoch: 4 [ 46080/ 50000 (92%)]\tLearning Rate: 0.000001\tLoss: 0.769467\n",
      "Train Epoch: 4 [ 48640/ 50000 (97%)]\tLearning Rate: 0.000000\tLoss: 0.679790\n",
      "\n",
      "Train set: Average loss: 0.7420, Accuracy: 37667/50000 (75%)\n",
      "Test set: Average loss: 1.0794, Accuracy: 6478/10000 (65%)\n",
      "\n",
      "Train Epoch: 5 [     0/ 50000 (0%)]\tLearning Rate: 0.001000\tLoss: 0.862297\n",
      "Train Epoch: 5 [  2560/ 50000 (5%)]\tLearning Rate: 0.001000\tLoss: 5.035945\n",
      "Train Epoch: 5 [  5120/ 50000 (10%)]\tLearning Rate: 0.000999\tLoss: 4.197534\n",
      "Train Epoch: 5 [  7680/ 50000 (15%)]\tLearning Rate: 0.000998\tLoss: 3.277235\n",
      "Train Epoch: 5 [ 10240/ 50000 (20%)]\tLearning Rate: 0.000996\tLoss: 3.142020\n",
      "Train Epoch: 5 [ 12800/ 50000 (26%)]\tLearning Rate: 0.000994\tLoss: 2.514402\n",
      "Train Epoch: 5 [ 15360/ 50000 (31%)]\tLearning Rate: 0.000991\tLoss: 2.141138\n",
      "Train Epoch: 5 [ 17920/ 50000 (36%)]\tLearning Rate: 0.000987\tLoss: 2.832106\n",
      "Train Epoch: 5 [ 20480/ 50000 (41%)]\tLearning Rate: 0.000984\tLoss: 2.315704\n",
      "Train Epoch: 5 [ 23040/ 50000 (46%)]\tLearning Rate: 0.000979\tLoss: 2.186405\n",
      "Train Epoch: 5 [ 25600/ 50000 (51%)]\tLearning Rate: 0.000975\tLoss: 2.257829\n",
      "Train Epoch: 5 [ 28160/ 50000 (56%)]\tLearning Rate: 0.000969\tLoss: 2.368894\n",
      "Train Epoch: 5 [ 30720/ 50000 (61%)]\tLearning Rate: 0.000963\tLoss: 3.133585\n",
      "Train Epoch: 5 [ 33280/ 50000 (66%)]\tLearning Rate: 0.000957\tLoss: 2.360738\n",
      "Train Epoch: 5 [ 35840/ 50000 (71%)]\tLearning Rate: 0.000950\tLoss: 2.543128\n",
      "Train Epoch: 5 [ 38400/ 50000 (77%)]\tLearning Rate: 0.000943\tLoss: 2.818899\n",
      "Train Epoch: 5 [ 40960/ 50000 (82%)]\tLearning Rate: 0.000936\tLoss: 2.282465\n",
      "Train Epoch: 5 [ 43520/ 50000 (87%)]\tLearning Rate: 0.000928\tLoss: 1.755311\n",
      "Train Epoch: 5 [ 46080/ 50000 (92%)]\tLearning Rate: 0.000919\tLoss: 2.382306\n",
      "Train Epoch: 5 [ 48640/ 50000 (97%)]\tLearning Rate: 0.000910\tLoss: 2.323264\n",
      "\n",
      "Train set: Average loss: 2.1245, Accuracy: 28018/50000 (56%)\n",
      "Test set: Average loss: 2.5649, Accuracy: 5076/10000 (51%)\n",
      "\n",
      "Train Epoch: 6 [     0/ 50000 (0%)]\tLearning Rate: 0.000905\tLoss: 2.048736\n",
      "Train Epoch: 6 [  2560/ 50000 (5%)]\tLearning Rate: 0.000895\tLoss: 1.599356\n",
      "Train Epoch: 6 [  5120/ 50000 (10%)]\tLearning Rate: 0.000885\tLoss: 1.424073\n",
      "Train Epoch: 6 [  7680/ 50000 (15%)]\tLearning Rate: 0.000874\tLoss: 1.833556\n",
      "Train Epoch: 6 [ 10240/ 50000 (20%)]\tLearning Rate: 0.000864\tLoss: 1.477587\n",
      "Train Epoch: 6 [ 12800/ 50000 (26%)]\tLearning Rate: 0.000852\tLoss: 1.386811\n",
      "Train Epoch: 6 [ 15360/ 50000 (31%)]\tLearning Rate: 0.000841\tLoss: 1.462109\n",
      "Train Epoch: 6 [ 17920/ 50000 (36%)]\tLearning Rate: 0.000829\tLoss: 1.680347\n",
      "Train Epoch: 6 [ 20480/ 50000 (41%)]\tLearning Rate: 0.000817\tLoss: 1.286411\n",
      "Train Epoch: 6 [ 23040/ 50000 (46%)]\tLearning Rate: 0.000804\tLoss: 1.287955\n",
      "Train Epoch: 6 [ 25600/ 50000 (51%)]\tLearning Rate: 0.000791\tLoss: 1.486943\n",
      "Train Epoch: 6 [ 28160/ 50000 (56%)]\tLearning Rate: 0.000778\tLoss: 1.452106\n",
      "Train Epoch: 6 [ 30720/ 50000 (61%)]\tLearning Rate: 0.000765\tLoss: 1.353430\n",
      "Train Epoch: 6 [ 33280/ 50000 (66%)]\tLearning Rate: 0.000751\tLoss: 1.377948\n",
      "Train Epoch: 6 [ 35840/ 50000 (71%)]\tLearning Rate: 0.000737\tLoss: 1.168939\n",
      "Train Epoch: 6 [ 38400/ 50000 (77%)]\tLearning Rate: 0.000723\tLoss: 1.460893\n",
      "Train Epoch: 6 [ 40960/ 50000 (82%)]\tLearning Rate: 0.000708\tLoss: 1.253953\n",
      "Train Epoch: 6 [ 43520/ 50000 (87%)]\tLearning Rate: 0.000694\tLoss: 1.175690\n",
      "Train Epoch: 6 [ 46080/ 50000 (92%)]\tLearning Rate: 0.000679\tLoss: 1.247402\n",
      "Train Epoch: 6 [ 48640/ 50000 (97%)]\tLearning Rate: 0.000664\tLoss: 1.211409\n",
      "\n",
      "Train set: Average loss: 1.2915, Accuracy: 32294/50000 (65%)\n",
      "Test set: Average loss: 1.8124, Accuracy: 5570/10000 (56%)\n",
      "\n",
      "Train Epoch: 7 [     0/ 50000 (0%)]\tLearning Rate: 0.000655\tLoss: 1.224954\n",
      "Train Epoch: 7 [  2560/ 50000 (5%)]\tLearning Rate: 0.000639\tLoss: 1.210450\n",
      "Train Epoch: 7 [  5120/ 50000 (10%)]\tLearning Rate: 0.000624\tLoss: 1.208506\n",
      "Train Epoch: 7 [  7680/ 50000 (15%)]\tLearning Rate: 0.000608\tLoss: 1.036621\n",
      "Train Epoch: 7 [ 10240/ 50000 (20%)]\tLearning Rate: 0.000592\tLoss: 0.989822\n",
      "Train Epoch: 7 [ 12800/ 50000 (26%)]\tLearning Rate: 0.000577\tLoss: 0.943115\n",
      "Train Epoch: 7 [ 15360/ 50000 (31%)]\tLearning Rate: 0.000561\tLoss: 0.927010\n",
      "Train Epoch: 7 [ 17920/ 50000 (36%)]\tLearning Rate: 0.000545\tLoss: 1.122867\n",
      "Train Epoch: 7 [ 20480/ 50000 (41%)]\tLearning Rate: 0.000529\tLoss: 1.204466\n",
      "Train Epoch: 7 [ 23040/ 50000 (46%)]\tLearning Rate: 0.000513\tLoss: 1.113516\n",
      "Train Epoch: 7 [ 25600/ 50000 (51%)]\tLearning Rate: 0.000497\tLoss: 0.995362\n",
      "Train Epoch: 7 [ 28160/ 50000 (56%)]\tLearning Rate: 0.000481\tLoss: 0.959756\n",
      "Train Epoch: 7 [ 30720/ 50000 (61%)]\tLearning Rate: 0.000465\tLoss: 1.026311\n",
      "Train Epoch: 7 [ 33280/ 50000 (66%)]\tLearning Rate: 0.000449\tLoss: 1.130288\n",
      "Train Epoch: 7 [ 35840/ 50000 (71%)]\tLearning Rate: 0.000433\tLoss: 0.985871\n",
      "Train Epoch: 7 [ 38400/ 50000 (77%)]\tLearning Rate: 0.000417\tLoss: 0.926984\n",
      "Train Epoch: 7 [ 40960/ 50000 (82%)]\tLearning Rate: 0.000401\tLoss: 1.045218\n",
      "Train Epoch: 7 [ 43520/ 50000 (87%)]\tLearning Rate: 0.000386\tLoss: 1.058718\n",
      "Train Epoch: 7 [ 46080/ 50000 (92%)]\tLearning Rate: 0.000370\tLoss: 0.941223\n",
      "Train Epoch: 7 [ 48640/ 50000 (97%)]\tLearning Rate: 0.000355\tLoss: 1.004047\n",
      "\n",
      "Train set: Average loss: 0.7457, Accuracy: 37796/50000 (76%)\n",
      "Test set: Average loss: 1.2989, Accuracy: 6239/10000 (62%)\n",
      "\n",
      "Train Epoch: 8 [     0/ 50000 (0%)]\tLearning Rate: 0.000345\tLoss: 0.642610\n",
      "Train Epoch: 8 [  2560/ 50000 (5%)]\tLearning Rate: 0.000330\tLoss: 0.639223\n",
      "Train Epoch: 8 [  5120/ 50000 (10%)]\tLearning Rate: 0.000315\tLoss: 0.748541\n",
      "Train Epoch: 8 [  7680/ 50000 (15%)]\tLearning Rate: 0.000301\tLoss: 0.605149\n",
      "Train Epoch: 8 [ 10240/ 50000 (20%)]\tLearning Rate: 0.000286\tLoss: 0.872988\n",
      "Train Epoch: 8 [ 12800/ 50000 (26%)]\tLearning Rate: 0.000272\tLoss: 0.648729\n",
      "Train Epoch: 8 [ 15360/ 50000 (31%)]\tLearning Rate: 0.000257\tLoss: 0.754720\n",
      "Train Epoch: 8 [ 17920/ 50000 (36%)]\tLearning Rate: 0.000244\tLoss: 0.728745\n",
      "Train Epoch: 8 [ 20480/ 50000 (41%)]\tLearning Rate: 0.000230\tLoss: 0.754534\n",
      "Train Epoch: 8 [ 23040/ 50000 (46%)]\tLearning Rate: 0.000217\tLoss: 0.614216\n",
      "Train Epoch: 8 [ 25600/ 50000 (51%)]\tLearning Rate: 0.000204\tLoss: 0.795709\n",
      "Train Epoch: 8 [ 28160/ 50000 (56%)]\tLearning Rate: 0.000191\tLoss: 0.759687\n",
      "Train Epoch: 8 [ 30720/ 50000 (61%)]\tLearning Rate: 0.000178\tLoss: 0.738851\n",
      "Train Epoch: 8 [ 33280/ 50000 (66%)]\tLearning Rate: 0.000166\tLoss: 0.787230\n",
      "Train Epoch: 8 [ 35840/ 50000 (71%)]\tLearning Rate: 0.000154\tLoss: 0.632993\n",
      "Train Epoch: 8 [ 38400/ 50000 (77%)]\tLearning Rate: 0.000143\tLoss: 0.737085\n",
      "Train Epoch: 8 [ 40960/ 50000 (82%)]\tLearning Rate: 0.000132\tLoss: 0.559446\n",
      "Train Epoch: 8 [ 43520/ 50000 (87%)]\tLearning Rate: 0.000121\tLoss: 0.753456\n",
      "Train Epoch: 8 [ 46080/ 50000 (92%)]\tLearning Rate: 0.000111\tLoss: 0.606908\n",
      "Train Epoch: 8 [ 48640/ 50000 (97%)]\tLearning Rate: 0.000101\tLoss: 0.572294\n",
      "\n",
      "Train set: Average loss: 0.6136, Accuracy: 39903/50000 (80%)\n",
      "Test set: Average loss: 1.1557, Accuracy: 6500/10000 (65%)\n",
      "\n",
      "Train Epoch: 9 [     0/ 50000 (0%)]\tLearning Rate: 0.000095\tLoss: 0.573525\n",
      "Train Epoch: 9 [  2560/ 50000 (5%)]\tLearning Rate: 0.000086\tLoss: 0.549305\n",
      "Train Epoch: 9 [  5120/ 50000 (10%)]\tLearning Rate: 0.000077\tLoss: 0.560465\n",
      "Train Epoch: 9 [  7680/ 50000 (15%)]\tLearning Rate: 0.000069\tLoss: 0.598496\n",
      "Train Epoch: 9 [ 10240/ 50000 (20%)]\tLearning Rate: 0.000061\tLoss: 0.715811\n",
      "Train Epoch: 9 [ 12800/ 50000 (26%)]\tLearning Rate: 0.000054\tLoss: 0.738278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [ 15360/ 50000 (31%)]\tLearning Rate: 0.000047\tLoss: 0.651075\n",
      "Train Epoch: 9 [ 17920/ 50000 (36%)]\tLearning Rate: 0.000040\tLoss: 0.599322\n",
      "Train Epoch: 9 [ 20480/ 50000 (41%)]\tLearning Rate: 0.000034\tLoss: 0.673050\n",
      "Train Epoch: 9 [ 23040/ 50000 (46%)]\tLearning Rate: 0.000029\tLoss: 0.561582\n",
      "Train Epoch: 9 [ 25600/ 50000 (51%)]\tLearning Rate: 0.000023\tLoss: 0.579881\n",
      "Train Epoch: 9 [ 28160/ 50000 (56%)]\tLearning Rate: 0.000019\tLoss: 0.581424\n",
      "Train Epoch: 9 [ 30720/ 50000 (61%)]\tLearning Rate: 0.000015\tLoss: 0.782312\n",
      "Train Epoch: 9 [ 33280/ 50000 (66%)]\tLearning Rate: 0.000011\tLoss: 0.591047\n",
      "Train Epoch: 9 [ 35840/ 50000 (71%)]\tLearning Rate: 0.000008\tLoss: 0.462567\n",
      "Train Epoch: 9 [ 38400/ 50000 (77%)]\tLearning Rate: 0.000005\tLoss: 0.575339\n",
      "Train Epoch: 9 [ 40960/ 50000 (82%)]\tLearning Rate: 0.000003\tLoss: 0.549632\n",
      "Train Epoch: 9 [ 43520/ 50000 (87%)]\tLearning Rate: 0.000002\tLoss: 0.566401\n",
      "Train Epoch: 9 [ 46080/ 50000 (92%)]\tLearning Rate: 0.000001\tLoss: 0.502077\n",
      "Train Epoch: 9 [ 48640/ 50000 (97%)]\tLearning Rate: 0.000000\tLoss: 0.667980\n",
      "\n",
      "Train set: Average loss: 0.5779, Accuracy: 40631/50000 (81%)\n",
      "Test set: Average loss: 1.1179, Accuracy: 6541/10000 (65%)\n",
      "\n",
      "\u001b[92mSaved trained model to:\u001b[0m\n",
      "/scratch/gpfs/stuli/cnnbench_models/CIFAR10/68510bcf50e51d05fef802b1af7a08334b76275fae640836ceb787e5af9dcd65/model.pt\n"
     ]
    }
   ],
   "source": [
    "from model_trainer import worker\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Training model:')\n",
    "print(graphLib.library[1])\n",
    "print()\n",
    "\n",
    "worker(graphLib.config, graphLib.library[1], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesing model: lenet\n",
      "\tModel params: 11519784\n",
      "Tesing model: alexnet\n",
      "\tModel params: 5931478\n",
      "Tesing model: vgg11\n",
      "\tModel params: 15078934\n",
      "Tesing model: vgg13\n",
      "\tModel params: 15272214\n",
      "Tesing model: vgg19\n",
      "\tModel params: 26748694\n",
      "Tesing model: resnet18\n",
      "\tModel params: 12500502\n",
      "Tesing model: resnet34\n",
      "\tModel params: 24297686\n",
      "Tesing model: resnet50\n",
      "\tModel params: 62694422\n",
      "Tesing model: resnet101\n",
      "\tModel params: 126294550\n",
      "Tesing model: resnet152\n",
      "\tModel params: 178676758\n",
      "Tesing model: shufflenet\n",
      "\tModel params: 40371598\n",
      "Tesing model: mobilenet\n",
      "\tModel params: 11953622\n",
      "Tesing model: googlenet\n",
      "\tModel params: 25794326\n"
     ]
    }
   ],
   "source": [
    "import manual_models\n",
    "\n",
    "for model_name in manual_models.SUPPORTED_MODELS:\n",
    "    print(f'Tesing model: {model_name}')\n",
    "    model_graph = manual_models.get_manual_graph(graphLib.config, model_name)\n",
    "    cnn_model = CNNBenchModel(graphLib.config, model_graph)\n",
    "    print(f'\\tModel params: {cnn_model.get_params()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txf_design-space [~/.conda/envs/txf_design-space/]",
   "language": "python",
   "name": "conda_txf_design-space"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
